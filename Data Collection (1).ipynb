{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58745c4-2956-4fac-a06f-0ab287f7d841",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c04a207-1f90-4b7c-b634-f07b7454ddf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Goal** : To classify and identify the location rice and non rice crop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6485f36d-ec3e-4cb9-b629-682196e0a13d",
   "metadata": {},
   "source": [
    "**Why Rice** : Rice is the primary crop and food staple of more than half the world’s population. Asia is the world’s largest rice-producing and rice-consuming region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5661859-5d1b-4339-a918-dc53297b18f2",
   "metadata": {},
   "source": [
    "<img src=\"Images\Rice Image.jpeg\" alt=\"alt text\" width=\"400\" height=\"300\" class=\"blog-image\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b25c9-571b-491a-a6aa-93f885b670a9",
   "metadata": {},
   "source": [
    "Researchers and government organizations routinely use satellite data to identify the location of agriculture crops and forecast yield. Unfortunately, there is no ideal solution that yields perfect results.With increasing publicly available sattelite data there is a steady progress happening in this field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41d0b4-f43d-47ed-8954-6d7a3b3b58be",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce73cc7-6227-45ee-8866-9b7469a1af7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here we obtain data from the following 2 sattelites :\n",
    "\n",
    "- The **Sentinel-1** mission(ESA) uses C-band **radar** at **10-meter** resolution with a single mission revisit every **12 days**.\n",
    "\n",
    "- The **Sentinel 2** is an Earth observation mission from the Copernicus Programme(ESA) that systematically acquires **optical imagery** at high spatial resolution over land and coastal waters. There are 2 sattelites which provides revisit every **5 days** at a particular location.\n",
    "\n",
    "<img src=\"Images/Sentinel-1_radar_vision_pillars.jpeg\" alt=\"alt text\" width=\"400\" height=\"300\" class=\"blog-image\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07eb771-ae39-4953-903f-e338e9130bc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analysis Region "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0261ad21-7cf4-44c6-b68b-05522e925a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "This project will use data from the **An Giang province** in the Mekong Delta in **Vietnam**. In particular, rice crop yield data was collected for the period of **late-2021 to mid-2022** over the **Chau Phu, Chau Thanh and Thoai Son districts**. This is a dense rice crop region with a mixture of double and triple cropping cycles. For this project we will assume triple cropping (3 cycles per year) with a focus on the **November-21 to April-22 and the April to August-22**.This data is spread evenly across these districts with nearly full coverage of each district. \n",
    "\n",
    "<img src=\"Images/Vietnam overview.jpeg\" alt=\"alt text\" width=\"500\" height=\"300\" class=\"blog-image\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e828a1dd-2739-4570-aa89-6d2509ea88c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## About the Data : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f180580-5bfd-457a-9655-d7429e44590d",
   "metadata": {},
   "source": [
    "The data was obtained from Microsoft Planetary hub through API. It was populated in the form of the data cube i.e. ndarray.\n",
    "\n",
    "<img src=\"Images/Data Cube.jpeg\" alt=\"alt text\" width=\"400\" height=\"300\" class=\"blog-image\">  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340355cc-839a-4c3a-b9b8-4812d6534ccc",
   "metadata": {},
   "source": [
    "Training data : Latitude and Longitude( Data of approx 600 locations)\n",
    "\n",
    "With the help of Stac(microsoft planetary hub) API , we obtain Optical data (e.g., Landsat or Sentinel-2).It contains many spectral bands **(e.g., Red, Green, Blue, Red-Edge, NIR, SWIR, etc.)** that can be related to the **presence or growth of rice crops**.Researchers often use **statistical combinations of these bands, called indices** to build models. One of the more common indices for agriculture is the **Normalized Difference Vegetation Index (NDVI)**, but there are many others including **Enhanced Vegetation Index (EVI)** and **Soil Adjusted Vegetation Index (SAVI)**. **Optical data is used to measure the \"greenness\" of vegetation during the growth cycle. Differences in band or index values can be used to distinguish differences in crop types.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f358f-7ea9-445a-82a4-07c775b4d615",
   "metadata": {},
   "source": [
    "Training data : Latitude and Longitude( Data of approx 600 locations)\n",
    "\n",
    "With the help of Stac(microsoft planetary hub) API , we obtain Optical data (e.g., Landsat or Sentinel-2).It contains many spectral bands **(e.g., Red, Green, Blue, Red-Edge, NIR, SWIR, etc.)** that can be related to the **presence or growth of rice crops**.Researchers often use **statistical combinations of these bands, called indices** to build models. One of the more common indices for agriculture is the **Normalized Difference Vegetation Index (NDVI)**, but there are many others including **Enhanced Vegetation Index (EVI)** and **Soil Adjusted Vegetation Index (SAVI)**. **Optical data is used to measure the \"greenness\" of vegetation during the growth cycle. Differences in band or index values can be used to distinguish differences in crop types.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8259541-b720-4672-ade9-0266d9620a0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "**NDVI (Normalized Difference Vegetation Index) = (NIR-Red) / (NIR+Red)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178026d6-d5a9-49ff-a179-fe05d3da5ddf",
   "metadata": {},
   "source": [
    "## Rice Phenology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57744757-71d3-4fba-afe6-efd065d0d81d",
   "metadata": {
    "tags": []
   },
   "source": [
    "This figure gives us an overview of the rice growth.\n",
    "\n",
    "<img src=\"Images/Rice stages.jpeg\" alt=\"alt text\" width=\"500\" height=\"300\" class=\"blog-image\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e683f-fb69-4d5f-842b-0d4a47bd3b70",
   "metadata": {
    "tags": []
   },
   "source": [
    "NVDI varies for every different surface rice crop,forest,river,orchad.\n",
    "\n",
    "<img src=\"Images/NVDI real.jpeg\" alt=\"alt text\" width=\"600\" height =\"400\" class =\"blog-image\">\n",
    "<img src=\"Images/NVDI word.jpeg\" alt=\"alt text\" width=\"500\" height=\"300\" class=\"blog-image\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac5738a-0bc9-41e8-8c64-290b4faa65a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Our Approach\n",
    "The typical approach considers data from setinent 1 satellite (radar) which involves vv and vh bands. However, in our approach we wanted to experiment with sentient 2 satellite (optical) data and try to draw out accurate findings.  \n",
    "Studying the rice phenology and dataset reveals that rice follows a **double cropping cycle in a year**. Each crop cycle has 3 main growing stages-   \n",
    "- Vegetative  \n",
    "- Reproductive  \n",
    "- Ripening   \n",
    "As shown above, the indices vary greatly during this time period. As our indices dataset is a time series data, we have divided dataset into 6 different parts i.e. **3 for each cycle**. This is our basic approach, we have further took 2 different approaches for feature selection.\n",
    "\n",
    "## Approach 1:\n",
    "We have considered multiple vegatative indices across all 6 time frames and calculated mean of each index for each time frame respective \n",
    "\n",
    "## Approach 2: \n",
    "We have considered a few most commonly used vegatative indices across all 6 time frames  then calculated mean as well as variance of each index for each time frame respective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c2dc12-c129-4161-9669-2b4318e5c51b",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56561c38-a3bf-4fbb-adf5-f9beddb30279",
   "metadata": {},
   "source": [
    "### Importing all the necessary Libraries important for processing and fetching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f6eea6-1a85-4275-80dd-16df7b4ed823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Supress Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import common GIS tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr # library for working with labeled multidimensional arrays.\n",
    "\n",
    "# Import Planetary Computer tools\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "import odc\n",
    "from odc.stac import stac_load\n",
    "from odc.algo import to_rgba\n",
    "from shapely.geometry import box\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import ipyleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "from dask.distributed import Client as daskClient\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac\n",
    "import pystac_client\n",
    "import odc\n",
    "from pystac_client import Client\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "from odc.stac import stac_load\n",
    "import planetary_computer as pc\n",
    "pc.settings.set_subscription_key('df2f4d7a411942f8a5b81d60cb9b95ca')\n",
    "\n",
    "# Others\n",
    "import requests\n",
    "import rich.table\n",
    "import math\n",
    "import random\n",
    "from itertools import cycle\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91f20597-25b2-4bb3-a1ad-4d614a21f324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude and Longitude</th>\n",
       "      <th>Class of Land</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.323727047081501, 105.2516346045924)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.322364360592521, 105.27843410554115)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.321455902933202, 105.25254306225168)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.324181275911162, 105.25118037576274)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.324635504740822, 105.27389181724476)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Latitude and Longitude Class of Land\n",
       "0   (10.323727047081501, 105.2516346045924)          Rice\n",
       "1  (10.322364360592521, 105.27843410554115)          Rice\n",
       "2  (10.321455902933202, 105.25254306225168)          Rice\n",
       "3  (10.324181275911162, 105.25118037576274)          Rice\n",
       "4  (10.324635504740822, 105.27389181724476)          Rice"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the provided CSV file\n",
    "\n",
    "get = pd.read_csv(\"Crop_Location_Data_20221201 (1).csv\")\n",
    "get.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e64c63-212f-46fb-ab7b-50cb1c3680cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spererating Longitude and Laditude and its type to float\n",
    "\n",
    "get[['Latitude','Longitude']] = get['Latitude and Longitude'].str.split(',',expand=True)\n",
    "get['Latitude'] = get['Latitude'].str.replace(r'\\(|\\)', '', regex=True)\n",
    "get['Longitude'] = get['Longitude'].str.replace(r'\\(|\\)', '', regex=True)\n",
    "\n",
    "get['Latitude'] = get['Latitude'].astype(float)\n",
    "get['Longitude'] = get['Longitude'].astype(float)\n",
    "get\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163efdd8-1ce0-4272-84d9-033ba6524857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference for what time slice to put\n",
    "\n",
    "vegetative = \"2021-11-01/2021-12-31\"\n",
    "reproductive = \"2022-01-01/2022-02-28\"\n",
    "ripening = \"2022-03-01/2022-04-30\"\n",
    "\n",
    "vegetative_2 = \"2022-04-01/2022-05-31\"\n",
    "reproductive_2 = \"2022-05-01/2022-06-30\"\n",
    "ripening_2 = \"2022-07-01/2022-08-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d4622-757f-4e59-a6db-237391401b61",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90450d13-cd72-4aea-830e-4c520253e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "def process_lat_lon(lat, lon):\n",
    "    box_size_deg = 0.0004 #5*5\n",
    "    time_window = \"2022-03-01/2022-04-30\"\n",
    "    resolution = 20\n",
    "    scale = resolution / 111320.0\n",
    "\n",
    "    # Calculate bounding box(min,max)\n",
    "    bbox = box(lon - box_size_deg / 2, lat - box_size_deg / 2, lon + box_size_deg / 2, lat + box_size_deg / 2)\n",
    "    \n",
    "    # Fetching the data through Sentinel-2\n",
    "    stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "    search = stac.search(collections=[\"sentinel-2-l2a\"], bbox=bbox.bounds, datetime=time_window)\n",
    "    items = list(search.get_all_items())\n",
    "    \n",
    "    # Fetching the bands/variables in an xarray\n",
    "    xx = stac_load(\n",
    "        items,\n",
    "        bands=[\"red\", \"green\", \"blue\", \"nir\", \"SCL\", \"B11\", \"B12\"],\n",
    "        crs=\"EPSG:4326\",\n",
    "        resolution=scale,\n",
    "        chunks={\"x\": 2048, \"y\": 2048},\n",
    "        dtype=\"uint16\",\n",
    "        patch_url=pc.sign,\n",
    "        bbox=bbox.bounds\n",
    "    )\n",
    "    \n",
    "    # Create a mask for no data, saturated data, clouds, cloud shadows, and water\n",
    "    cloud_mask = \\\n",
    "        (xx.SCL != 0) & \\\n",
    "        (xx.SCL != 1) & \\\n",
    "        (xx.SCL != 3) & \\\n",
    "        (xx.SCL != 6) & \\\n",
    "        (xx.SCL != 8) & \\\n",
    "        (xx.SCL != 9) & \\\n",
    "        (xx.SCL != 10)\n",
    "     \n",
    "    # Apply cloud mask\n",
    "    cleaned_data = xx.where(cloud_mask).astype(\"uint16\")\n",
    "    \n",
    "    resample_period = '1w'\n",
    "    window = 5\n",
    "    \n",
    "    \n",
    "    # Calculate the mean of the data across the sample region and then NDVI\n",
    "    mean_clean = cleaned_data.mean(dim=['longitude','latitude']).compute()\n",
    "    ndvi_mean_clean = (mean_clean.nir - mean_clean.red) / (mean_clean.nir + mean_clean.red)\n",
    "    interpolate_data = ndvi_mean_clean.to_dataframe(name='NDVI')\n",
    "    # Apply the rolling window operation\n",
    "    NDVI_interpolated = interpolate_data['NDVI'].resample(resample_period).median().rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "    # Calculate the mean of the data across the sample region and then EVI\n",
    "    evi_mean_clean = 2.5 * ((mean_clean.nir - mean_clean.red) / (mean_clean.nir + (6 * mean_clean.red) + (7.5 * mean_clean.blue) + 1))\n",
    "    interpolate_data = evi_mean_clean.to_dataframe(name='EVI')\n",
    "    # Apply the rolling window operation\n",
    "    EVI_interpolated = interpolate_data['EVI'].resample(resample_period).median().rolling(window=window, min_periods=1).mean()\n",
    "                      \n",
    "    # Calculate the mean of the data across the sample region and then RGVI\n",
    "    rgvi_mean_clean = 1 - ((mean_clean.blue - mean_clean.red) / (mean_clean.nir + mean_clean.B11 + mean_clean.B12))\n",
    "    interpolate_data = rgvi_mean_clean.to_dataframe(name='RGVI')\n",
    "    # Apply the rolling window operation\n",
    "    RGVI_interpolated = interpolate_data['RGVI'].resample(resample_period).median().rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    # Calculate the mean of the data across the sample region and then NDBI\n",
    "    ndbi_mean_clean = (mean_clean.B11 - mean_clean.nir) / (mean_clean.B11 + mean_clean.nir)\n",
    "    interpolate_data = ndbi_mean_clean.to_dataframe(name='NDBI')\n",
    "    # Apply the rolling window operation\n",
    "    NDBI_interpolated = interpolate_data['NDBI'].resample(resample_period).median().rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    # Calculate the mean of the data across the sample region and then DVI\n",
    "    dvi_mean_clean = mean_clean.nir - mean_clean.red\n",
    "    interpolate_data = dvi_mean_clean.to_dataframe(name='DVI')\n",
    "    # Apply the rolling window operation\n",
    "    DVI_interpolated = interpolate_data['DVI'].resample(resample_period).median().rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    # Calculate the mean of the data across the sample region and then IPVI\n",
    "    ipvi_mean_clean = (mean_clean.nir) / (mean_clean.nir + mean_clean.red)\n",
    "    interpolate_data = ipvi_mean_clean.to_dataframe(name='IPVI')\n",
    "    # Apply the rolling window operation\n",
    "    IPVI_interpolated = interpolate_data['IPVI'].resample(resample_period).median().rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    # Calculate the mean of the data across the sample region and then SAVI\n",
    "    #SAVI is modified NVDI which is used to correct the brightness from soil\n",
    "    L=0.5 #most commanly prefered value of correction factor\n",
    "    savi_mean_clean = (1+L)*(mean_clean.nir-mean_clean.red) / (mean_clean.nir + mean_clean.red+L)\n",
    "    interpolate_data = savi_mean_clean.to_dataframe(name='SAVI')\n",
    "    # Apply the rolling window operation\n",
    "    SAVI_interpolated = interpolate_data['SAVI'].resample(resample_period).median().rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    # Calculate the mean of the data across the sample region and then MSAVI\n",
    "    #MSAVI is modified MSAVI which is used to variable value of L depending on vegetation cover\n",
    "    msavi_mean_clean = (2*mean_clean.nir+1-np.sqrt((2*mean_clean.nir)**2-8*(mean_clean.nir-mean_clean.red)))/2\n",
    "    interpolate_data = msavi_mean_clean.to_dataframe(name='MSAVI')\n",
    "    # Apply the rolling window operation\n",
    "    MSAVI_interpolated = interpolate_data['MSAVI'].resample(resample_period).median().rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    # Calculate the mean of the data across the sample region and then NDWI\n",
    "    # Ususal for mapping water content on land; 0.5+ for water bodies\n",
    "    ndwi_mean_clean = (mean_clean.green-mean_clean.nir)/(mean_clean.green+mean_clean.nir)\n",
    "    interpolate_data = msavi_mean_clean.to_dataframe(name='NDWI')\n",
    "    # Apply the rolling window operation\n",
    "    NDWI_interpolated = interpolate_data['NDWI'].resample(resample_period).median().rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    # Calculate the mean of the data across the sample region and then LSWI\n",
    "    # Land surface water index\n",
    "    lswi_mean_clean = (mean_clean.nir-mean_clean.B11)/(mean_clean.nir-mean_clean.B11)\n",
    "    interpolate_data = lswi_mean_clean.to_dataframe(name='LSWI')\n",
    "    # Apply the rolling window operation\n",
    "    LSWI_interpolated = interpolate_data['LSWI'].resample(resample_period).median().rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "                   \n",
    "    return {\n",
    "        #mean \n",
    "        'NDVI': float(NDVI_interpolated.mean()),\n",
    "        'EVI': float(EVI_interpolated.mean()),\n",
    "        'RGVI': float(RGVI_interpolated.mean()),\n",
    "        'NDBI': float(ndbi_mean_clean.mean()),\n",
    "        'DVI': float(dvi_mean_clean.mean()),\n",
    "        'IPVI': float(ipvi_mean_clean.mean()),\n",
    "        'SAVI': float(SAVI_interpolated.mean()),\n",
    "        'MSAVI': float(MSAVI_interpolated.mean()),\n",
    "        'NDWI': float(NDWI_interpolated.mean()),\n",
    "        'LSWI': float(LSWI_interpolated.mean()),\n",
    "        #variances\n",
    "        'NDVI_var': float(NDVI_interpolated.var()),\n",
    "        'EVI_var': float(EVI_interpolated.var()),\n",
    "        'RGVI_var': float(RGVI_interpolated.var()),\n",
    "        'NDBI_var': float(ndbi_mean_clean.var()),\n",
    "        'DVI_var': float(dvi_mean_clean.var()),\n",
    "        'IPVI_var': float(ipvi_mean_clean.var()),\n",
    "        'SAVI_var': float(SAVI_interpolated.var()),\n",
    "        'MSAVI_var': float(MSAVI_interpolated.var()),\n",
    "        'NDWI_var': float(NDWI_interpolated.var()),\n",
    "        'LSWI_var': float(LSWI_interpolated.var())\n",
    "    }\n",
    "\n",
    "\n",
    "def process_lat_lon_batch(batch_df):\n",
    "    results = []\n",
    "\n",
    "    for index, row in batch_df.iterrows():\n",
    "        lat = row['Latitude']\n",
    "        lon = row['Longitude']\n",
    "\n",
    "        results.append(process_lat_lon(lat, lon))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Apply the processing function to latitude and longitude data in batches\n",
    "batch_size = 2\n",
    "lat_lon_batches = [get[['Latitude', 'Longitude']][i:i+batch_size] for i in range(0, len(get), batch_size)]\n",
    "\n",
    "results = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for result in executor.map(process_lat_lon_batch, lat_lon_batches):\n",
    "        results.extend(result)\n",
    "        \n",
    "# Create a DataFrame from the results\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv('ripening.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58135018-12bc-4f5e-8274-d76afed86810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
